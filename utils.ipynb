{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "663e6018",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from ipynb.fs.full.backtracking_algo import *\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84bab621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thresholding(img):\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    edges = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    edges = cv2.morphologyEx(edges, cv2.MORPH_OPEN, kernel)\n",
    "    thres = cv2.adaptiveThreshold(edges, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 7, 7)\n",
    "    thres = cv2.resize(thres, (800, 800))\n",
    "    return thres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699760d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_img(img):\n",
    "    contours , _ = cv2.findContours(img , cv2.RETR_TREE , cv2.CHAIN_APPROX_SIMPLE)\n",
    "    biggest = np.array([])\n",
    "    max_area = 0\n",
    "    for i in contours:\n",
    "        area = cv2.contourArea(i)\n",
    "        if area > 1000:\n",
    "            peri = cv2.arcLength(i, True)\n",
    "            approx = cv2.approxPolyDP(i, 0.02 * peri, True)\n",
    "            if area > max_area and len(approx) == 4:\n",
    "                biggest = approx\n",
    "                max_area = area\n",
    "    pts = biggest.reshape(4, 2)\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    (tl, tr, br, bl) = rect\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "    maxHeight = maxWidth\n",
    "    dst = np.array([\n",
    "    [0, 0],\n",
    "    [maxWidth - 1, 0],\n",
    "    [maxWidth - 1, maxHeight - 1],\n",
    "    [0, maxHeight - 1]], dtype = \"float32\")\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(img, M, (maxWidth, maxHeight))\n",
    "    return warped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbc3c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_Cell(image):\n",
    "    image_height = image.shape[0]\n",
    "    image_width = image.shape[1]\n",
    "    cell_height  = image_height // 9 \n",
    "    cell_width = image_width // 9 \n",
    "    rects = []\n",
    "    cells = []\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            p1 = (j*cell_height , i*cell_width)\n",
    "            p2 = ((j+1)*cell_height , (i+1)*cell_width)\n",
    "            rects.append((p1, p2))\n",
    "            cv2.rectangle(image, p1, p2, (255,0,0),3)\n",
    "    for coords in rects:\n",
    "        rect = image[coords[0][1]:coords[1][1], coords[0][0]:coords[1][0]]\n",
    "        cells.append(rect)\n",
    "    return cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0dd8cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_tile(img):\n",
    "    height , width = img.shape[:2]\n",
    "    start_r , start_c = int(height*0.15) , int(width*0.15)\n",
    "    end_r , end_c = int(height*0.85) , int(width*0.85)\n",
    "    cropped = img[start_r:end_r , start_c:end_c]\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb02028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLAINED ON : https://medium.com/@o.kroeger/tensorflow-mnist-and-your-own-handwritten-digits-4d1cd32bbab4\n",
    "def get_text_center(img):\n",
    "    gray = cv2.resize(img , (28,28))\n",
    "\n",
    "    while np.sum(gray[0]) == 0:\n",
    "        gray = gray[1:]\n",
    "\n",
    "    while np.sum(gray[:,0]) == 0:\n",
    "        gray = np.delete(gray,0,1)\n",
    "\n",
    "    while np.sum(gray[-1]) == 0:\n",
    "        gray = gray[:-1]\n",
    "\n",
    "    while np.sum(gray[:,-1]) == 0:\n",
    "         gray = np.delete(gray,-1,1)\n",
    "\n",
    "    rows,cols = gray.shape\n",
    "\n",
    "    if rows > cols:\n",
    "        factor = 20.0/rows\n",
    "        rows = 20\n",
    "        cols = int(round(cols*factor))\n",
    "        gray = cv2.resize(gray, (cols,rows))\n",
    "    else:\n",
    "        factor = 20.0/cols\n",
    "        cols = 20\n",
    "        rows = int(round(rows*factor))\n",
    "        gray = cv2.resize(gray, (cols, rows))\n",
    "\n",
    "    colsPadding = (int(math.ceil((28-cols)/2.0)),int(math.floor((28-cols)/2.0)))\n",
    "    rowsPadding = (int(math.ceil((28-rows)/2.0)),int(math.floor((28-rows)/2.0)))\n",
    "    gray = np.lib.pad(gray,(rowsPadding,colsPadding),'constant')\n",
    "    return gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "952a4941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBestShift(img):\n",
    "    cy,cx = ndimage.measurements.center_of_mass(img)\n",
    "\n",
    "    rows,cols = img.shape\n",
    "    shiftx = np.round(cols/2.0-cx).astype(int)\n",
    "    shifty = np.round(rows/2.0-cy).astype(int)\n",
    "\n",
    "    return shiftx,shifty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4ed2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shift(img,sx,sy):\n",
    "    rows,cols = img.shape\n",
    "    M = np.float32([[1,0,sx],[0,1,sy]])\n",
    "    shifted = cv2.warpAffine(img,M,(cols,rows))\n",
    "    return shifted\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7297f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "          \n",
    "def beautiful_graphics_version2(grid,old_grid):\n",
    "    answer_frame = np.ones((450,450,3), np.uint8)\n",
    "    # answer_frame = np.zeros([450,450,3],dtype=np.uint8)\n",
    "    # answer_frame.fill(255)\n",
    "    height = 50\n",
    "    width = 50\n",
    "    th = 2\n",
    "    font_scale = 2\n",
    "    font_th = 2\n",
    "    font_letter = cv2.FONT_HERSHEY_PLAIN\n",
    "    for i in range(9):\n",
    "        for j in range(9):\n",
    "            text = str(grid[i][j])\n",
    "            old_text = str(old_grid[i][j])\n",
    "            x = width*j\n",
    "            y = height*i\n",
    "            cv2.rectangle(answer_frame, (x + th, y + th), (x + width - th, y + height - th), (255,255,255), th)\n",
    "            text_size = cv2.getTextSize(text, font_letter, font_scale, font_th)[0]\n",
    "            width_text, height_text = text_size[0], text_size[1]\n",
    "            text_x = int((width - width_text) / 2) + x\n",
    "            text_y = int((height + height_text) / 2) + y\n",
    "            if text == old_text:\n",
    "                cv2.putText(answer_frame, text, (text_x, text_y), font_letter, font_scale, (0,0,255), font_th)\n",
    "            else:\n",
    "                cv2.putText(answer_frame, text, (text_x, text_y), font_letter, font_scale, (255, 255, 0), font_th)\n",
    "    \n",
    "    return answer_frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ba2addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_result(path):\n",
    "    model = load_model('digit.h5')\n",
    "    img = cv2.imread(path)\n",
    "    p_img = thresholding(img)\n",
    "    wrapped_img = wrap_img(p_img )\n",
    "    tiles = split_Cell(wrapped_img)\n",
    "    digits_highlight = []\n",
    "    predictions = []\n",
    "    for tile in tiles:\n",
    "\n",
    "        crop = crop_tile(tile)\n",
    "        count_white_pixles = cv2.countNonZero(crop)\n",
    "        \n",
    "        if count_white_pixles > 150 :\n",
    "            centered_Text = get_text_center(crop)\n",
    "            img = cv2.resize(centered_Text,(28,28))\n",
    "            img = img.reshape((1,28,28,1))\n",
    "            x = img.astype('float32')/255\n",
    "            result = model.predict(x)\n",
    "            index = np.argmax(result) + 1\n",
    "            predictions.append(index)\n",
    "            digits_highlight.append(index)\n",
    "            \n",
    "        else:\n",
    "            x = 0\n",
    "            predictions.append(x)\n",
    "            digits_highlight.append(x)\n",
    "\n",
    "    board = np.array(predictions).reshape((9, 9))\n",
    "    solver = BackTracing(board)\n",
    "    solver.solve()\n",
    "    final = solver.bo\n",
    "    board_h = np.array(digits_highlight).reshape((9, 9))\n",
    "    final_result = beautiful_graphics_version2(final,board_h)\n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4375a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d943c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
